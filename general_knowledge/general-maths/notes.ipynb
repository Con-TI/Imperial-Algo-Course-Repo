{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff27374",
   "metadata": {},
   "source": [
    "# Basic Probability concepts\n",
    "\n",
    "### Sample space, Sigma algebra, and Probability measures\n",
    "\n",
    "Sample space\n",
    "\n",
    "Algebras and Sigma algebras\n",
    "\n",
    "Probability measures\n",
    "\n",
    "Common definitions for probability measures:\n",
    "\n",
    "### De Morgan's Laws\n",
    "\n",
    "### Inclusion-Exclusion principle\n",
    "\n",
    "### Combinatoric vs Probabilistic views\n",
    "Combinations\n",
    "\n",
    "Permutations\n",
    "\n",
    "Stars and Bars\n",
    "\n",
    "Derangements\n",
    "\n",
    "Examples of viewpoint differences:\n",
    "\n",
    "### Filtrations\n",
    "\n",
    "### Random variables as functions, PMFs/PDFs and CDFs\n",
    "Discrete RVs\n",
    "\n",
    "Continuous RVs\n",
    "\n",
    "Independence between RVs\n",
    "\n",
    "### Expectation and Variance\n",
    "Expectation\n",
    "\n",
    "Variance \n",
    "\n",
    "Law of the unconscious statistician (LOTUS)\n",
    "\n",
    "Law of total expectation\n",
    "\n",
    "Law of total variance\n",
    "\n",
    "Tail integrals\n",
    "\n",
    "Indicator RVs\n",
    "\n",
    "Geometric sums\n",
    "\n",
    "Combinatoric view vs Probabilitic view\n",
    "\n",
    "### Covariance and Correlation\n",
    "Covariance\n",
    "\n",
    "Correlation\n",
    "\n",
    "Independence vs correlation\n",
    "\n",
    "### Limit definitions for random variables\n",
    "\n",
    "### Conditional Probability\n",
    "Joint and Marginal probability functions\n",
    "\n",
    "Bayes theorem\n",
    "\n",
    "### Common distributions\n",
    "Uniform\n",
    "\n",
    "Bernoulli\n",
    "\n",
    "Binomial\n",
    "\n",
    "Negative Binomial\n",
    "\n",
    "Geometric\n",
    "\n",
    "Hypergeometric\n",
    "\n",
    "Exponential\n",
    "\n",
    "Poisson\n",
    "\n",
    "Normal\n",
    "\n",
    "Bivariate Normal\n",
    "\n",
    "Chi-square\n",
    "\n",
    "Beta\n",
    "\n",
    "Gamma\n",
    "\n",
    "Relations between the distributions\n",
    "\n",
    "Laws of Large Numbers\n",
    "\n",
    "Central Limit Theorem\n",
    "\n",
    "Projection theorem for normal RVs\n",
    "\n",
    "Additivitity rules between independent RVs\n",
    "\n",
    "Symmetries in probability distributions\n",
    "\n",
    "### Kth Moment, Moment Generating functions, Probability generating functions\n",
    "\n",
    "Kth Moment\n",
    "\n",
    "MGF\n",
    "\n",
    "PGF\n",
    "\n",
    "### Order statistics\n",
    "\n",
    "\n",
    "### Vector/Matrices extensions and definitions\n",
    "Stochastic matrices\n",
    "\n",
    "Positive definite matrices\n",
    "\n",
    "Positive-semi definite matrices\n",
    "\n",
    "Correlation matrix\n",
    "\n",
    "Covariance matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60895c90",
   "metadata": {},
   "source": [
    "# Important Inequalities\n",
    "\n",
    "Markov\n",
    "\n",
    "Chebyshev\n",
    "\n",
    "Limit on variance\n",
    "\n",
    "Bounds on correlation\n",
    "\n",
    "Convexity and concavity\n",
    "\n",
    "Jensen's inequality\n",
    "\n",
    "Triangle inequality\n",
    "\n",
    "Cauchy Schwarz inequality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7179b0c6",
   "metadata": {},
   "source": [
    "# Matrix decomposition\n",
    "### LU\n",
    "\n",
    "### QR\n",
    "\n",
    "### SVD\n",
    "\n",
    "### Eigenvalue decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708f4b9d",
   "metadata": {},
   "source": [
    "# Derivatives with respect to vectors\n",
    "### Gradient, Divergence and curl\n",
    "\n",
    "### Hessian\n",
    "\n",
    "### Jacobian\n",
    "\n",
    "### Laplacian\n",
    "\n",
    "### Differentiation rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe2d5a5",
   "metadata": {},
   "source": [
    "# Linear Recurrence relations\n",
    "Recurrence relations often appear in markov chain related problems among others and hence knowing the methods behind solving specific types of them are useful to know.\n",
    "\n",
    "### Definition\n",
    "A **linear recurrence relation** defines each term as a combination of previous terms. It has general form:\n",
    "\\begin{equation*}\n",
    "x_n = a_1x_{n-1} + a_2x_{n-2}+...+a_kx_{n-k} + f(n)\n",
    "\\end{equation*}\n",
    "where $a_1, a_2,...,a_k$ are coefficients and $f(n)$ is the non-recursive term. \n",
    "\n",
    "Recurrence relations are classified based on three main things:\n",
    "- Homogeneity: If $f(n) = 0$, the recurrence relation is homogeneous. Otherwise it is not.\n",
    "- Constant vs Variable coefficients: if $a_i$ do not vary with $n$ then the coefficients are constant.\n",
    "- Order: A kth-order relation means that $x_n$ is a function of $x_{n-1}$ up to $x_{n-k}$.\n",
    "\n",
    "### Solving constant, homogeneous linear recurrences:\n",
    "Given the kth-order relation\n",
    "\\begin{equation*}\n",
    "x_n = a_1x_{n-1} + a_2x_{n-2}+...+a_kx_{n-k}\n",
    "\\end{equation*}\n",
    "we have the following **characteristic polynomial**\n",
    "\\begin{equation*}\n",
    "r^k = a_1r^{k-1} + a_2r^{k-2}+...+a_k\n",
    "\\end{equation*}\n",
    "\n",
    "We will denote x^{(h)}_n as the general solution to the homogeneous system. We have three cases of solutions to the characteristic polynomial:\n",
    "#### Case 1:\n",
    "If the characteristic equation has $k$ distinct roots $r_1, r_2,...,r_k$, then the general solution is given by:\n",
    "\\begin{equation*}\n",
    "x_n=\\sum_{j=1}^k{A_jr_j^n}\n",
    "\\end{equation*}\n",
    "where substituting the initial conditions provides the values of the unknown coefficients $A_1,...,A_k$.\n",
    "\n",
    "#### Case 2:\n",
    "If the characteristic equation has repeated roots, then given $r_1,...,r_p$ with multiplicities $m_1,..,m_p$ that sum to $k$, we have the general solution:\n",
    "\\begin{equation*}\n",
    "x_n=\\sum_{j=1}^p\\sum_{i=0}^{m_j-1}A_{j,i}n^ir^n_j=A_{1,0}r^n_1+..+A_{1,m_1-1}n^{m_1-1}r^n_1+A_{2,0}r^2_j...+A_{p,m_p-1}n^{m_p-1}r^n_p\n",
    "\\end{equation*}\n",
    "\n",
    "#### Case 3:\n",
    "If the characteristic equation has complex roots, then each of the complex conjugate pairs $\\alpha\\pm i\\beta$ contributes the following term to the general solution (letting $r$ denote $\\alpha+i\\beta$):\n",
    "\\begin{equation*}\n",
    "x_n=...+|r|^n(B\\cos{(n \\arg(r))}+C\\sin{(n \\arg(r))})\n",
    "\\end{equation*}\n",
    "where $|r|^2=\\alpha^2+\\beta^2$ and $\\arg(r)=\\arctan{\\beta/\\alpha}$.\n",
    "\n",
    "### Inhomogeneous linear recurrences\n",
    "In general, the solution to an inhomogeneous system is given by: $x_n^{GS}=x_n^{(h)}+x_n^{(p)}$ where $x^{(h)}_n$ denotes the homogeneous solution and x_n^{(p)} the particular solution. So the main extension is to solve the particular solution. This can typically be done by **Ansatz** which is the process of guessing a solution form (e.g. $x_n=A_0+A_1n+A_2n^2$) based on what $f(n)$ looks like then substituting to solve for the coefficients.\n",
    "\n",
    "### Green's function approach for linear recurrences:\n",
    "Green's function $G$ is the impulse response of an inhomogeneous linear differential operator $L$ (ODEs/Difference equations/Recurrence relations/etc.).\n",
    "\\begin{equation*}\n",
    "LG=\\delta\n",
    "\\end{equation*}\n",
    "where $\\delta$ is the dirac delta function (defined by $\\int_{-k}^k\\delta(x)dx=1, \\forall k$).\n",
    "\n",
    "In the case of a linear recurrence relation, we have the equation $Lx_n = f(n)$ that gives us:\n",
    "\\begin{equation*}\n",
    "LG(n,m) = \\delta_{n,m} = \\begin{cases} 1 & \\text{if } n=m \\\\ 0 & \\text{otherwise} \\end{cases}\n",
    "\\end{equation*}\n",
    "where $\\delta_{n,m}$ is the discrete dirac delta. The solution to the linear recurrence is then given by:\n",
    "\\begin{equation*}\n",
    "x_n = \\sum_{m}G(n,m)f(m)\n",
    "\\end{equation*}\n",
    "\n",
    "Note that when solving for G(n,m), it may be necessary to specify two equations for G depending on $n<m$, $n=m$ and $n>m$ and to assume continuity at $n=m$. The solution to the equation $LG(n,m) = \\delta_{n,m}$ is then just a matter of solving a homogeneous linear recurrence relation.\n",
    "\n",
    "### Extension:\n",
    "Methods for solving linear recurrence relations have many analogues in linear ODE/PDE systems and linear difference equations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e9d6c",
   "metadata": {},
   "source": [
    "# Concepts in Random walks\n",
    "\n",
    "### Markov Property\n",
    "\n",
    "### Martingales\n",
    "\n",
    "### Stopping time and the Optional Stopping Theorem\n",
    "\n",
    "### Mean reverting walks\n",
    "\n",
    "### Random walk on a graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8aa1f",
   "metadata": {},
   "source": [
    "# Markov chains [[src](https://www.statslab.cam.ac.uk/~rrw1/markov/M.pdf)]\n",
    "\n",
    "### Definition\n",
    "For a markov chain, we have the following components:\n",
    "- The **probability space** $(\\Omega, \\mathcal{F}, \\mathbb{P})$.\n",
    "- A countable set $\\mathcal{I}$ which denotes our set of possible states in the **state-space**\n",
    "- The sequence of random variables $X_0, X_1,...\\in \\mathcal{I}$ representing our **markov chain** $(X_n)_{n\\geq 0}$. This can be understood as the path the random process takes\n",
    "- A row vector $\\lambda$ representing the initial distirbution over $\\mathcal{I}$ (i.e. $\\mathbb{P}(X_0=i_0)=\\lambda_i \\forall i\\in\\mathcal{I}$).\n",
    "- A stochastic matrix (meaning all entries are $\\geq 0$) known as the **transition matrix** $P$.\n",
    "Denote a markov chain following $\\lambda$ and $P$ by $Markov(\\lambda, P)$ The entry $(P){ij}=p_{ij}$ (in row $i$ and column $j$) represents the probability of transitioning from state $i$ to state $j$.\n",
    "\n",
    "### Probabilities on a Markov Chain\n",
    "Below are the basic probability rules governing a basic Markov chain\n",
    "\\begin{array}{rl}\n",
    "    \\mathbb{P}(X_0=i_0,...,X_n=i_n) &= \\lambda_{i_0}p_{i_0i_1}...p_{i_{n-1}i_n} \\\\\\\\\n",
    "    \\mathbb{P}(X_n=i_n|X_0=i_0,...,X_{n-1}=i_{n-1})&=\\mathbb{P}(X_n=i_n|X_{n-1}=i_{n-1})=p_{i_{n-1},i_n} \\text{ (Markov property)} \\\\\\\\\n",
    "    \\mathbb{P}(X_2=j|X_0=i) &= \\sum_k{p_{ik}p_{kj}}=(P^2)_{ij} \\text{ (conditioned 2-step transition)} \\\\\\\\\n",
    "    \\mathbb{P}(X_2) &= \\sum_{i}\\lambda_i\\mathbb{P}(X_2=j|X_0=i) \\text{ (2-step transition)} \\\\\\\\\n",
    "    \\mathbb{P}(X_n=j|X_0=i) &= \\sum_{i_1,...,i_n}p_{ii_1}...p_{i_{n-1}i_n} = (P^n)_{ij} \\text{ (conditioned n-step transition)} \\\\\\\\\n",
    "    \\mathbb{P}(X_n=j) &= \\sum_{i_0,...,i_n}\\lambda_{i_0}p_{i_0i_1}...p_{i_{n-1}i_n} = (\\lambda P^n)_j \\text{ (n-step transition)} \\\\\\\\\n",
    "    (P^{n+m})_{ij} &= \\sum_k{P_{ik}^nP_{kj}^m} \\text{ (Chapman Kolmogorov equation)}\n",
    "\\end{array}\n",
    "\n",
    "### Stationary Distributions\n",
    "\n",
    "\n",
    "### Absorbing states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24561a1e",
   "metadata": {},
   "source": [
    "# CTMC [[src]()]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
